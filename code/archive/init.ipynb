{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETSET initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, pandas as pd, numpy as np, json, copy, zipfile\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#suppres warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country and region name converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#country name converters\n",
    "\n",
    "#EIA->pop\n",
    "clist1={'North America':'Northern America',\n",
    "'United States':'United States of America',\n",
    "'Central & South America':'Latin America and the Caribbean',\n",
    "'Bahamas, The':'Bahamas',\n",
    "'Saint Vincent/Grenadines':'Saint Vincent and the Grenadines',\n",
    "'Venezuela':'Venezuela (Bolivarian Republic of)',\n",
    "'Macedonia':'The former Yugoslav Republic of Macedonia',\n",
    "'Moldova':'Republic of Moldova',\n",
    "'Russia':'Russian Federation',\n",
    "'Iran':'Iran (Islamic Republic of)',\n",
    "'Palestinian Territories':'State of Palestine',\n",
    "'Syria':'Syrian Arab Republic',\n",
    "'Yemen':'Yemen ',\n",
    "'Congo (Brazzaville)':'Congo',\n",
    "'Congo (Kinshasa)':'Democratic Republic of the Congo',\n",
    "'Cote dIvoire (IvoryCoast)':\"C\\xc3\\xb4te d'Ivoire\",\n",
    "'Gambia, The':'Gambia',\n",
    "'Libya':'Libyan Arab Jamahiriya',\n",
    "'Reunion':'R\\xc3\\xa9union',\n",
    "'Somalia':'Somalia ',\n",
    "'Sudan and South Sudan':'Sudan',\n",
    "'Tanzania':'United Republic of Tanzania',\n",
    "'Brunei':'Brunei Darussalam',\n",
    "'Burma (Myanmar)':'Myanmar',\n",
    "'Hong Kong':'China, Hong Kong Special Administrative Region',\n",
    "'Korea, North':\"Democratic People's Republic of Korea\",\n",
    "'Korea, South':'Republic of Korea',\n",
    "'Laos':\"Lao People's Democratic Republic\",\n",
    "'Macau':'China, Macao Special Administrative Region',\n",
    "'Timor-Leste (East Timor)':'Timor-Leste',\n",
    "'Virgin Islands,  U.S.':'United States Virgin Islands',\n",
    "'Vietnam':'Viet Nam'}\n",
    "\n",
    "#BP->pop\n",
    "clist2={u'                 European Union #':u'Europe',\n",
    "u'Rep. of Congo (Brazzaville)':u'Congo (Brazzaville)',\n",
    "'Republic of Ireland':'Ireland',\n",
    "'China Hong Kong SAR':'China, Hong Kong Special Administrative Region',\n",
    "u'Total Africa':u'Africa',\n",
    "u'Total North America':u'Northern America',\n",
    "u'Total S. & Cent. America':'Latin America and the Caribbean',\n",
    "u'Total World':u'World',\n",
    "u'Total World ':u'World',\n",
    "'South Korea':'Republic of Korea',\n",
    "u'Trinidad & Tobago':u'Trinidad and Tobago',\n",
    "u'US':u'United States of America'}\n",
    "\n",
    "#WD->pop\n",
    "clist3={u\"Cote d'Ivoire\":\"C\\xc3\\xb4te d'Ivoire\",\n",
    "u'Congo, Rep.':u'Congo (Brazzaville)',\n",
    "u'Caribbean small states':'Carribean',\n",
    "u'East Asia & Pacific (all income levels)':'Eastern Asia',\n",
    "u'Egypt, Arab Rep.':'Egypt',\n",
    "u'European Union':u'Europe',\n",
    "u'Hong Kong SAR, China':u'China, Hong Kong Special Administrative Region',\n",
    "u'Iran, Islamic Rep.':u'Iran (Islamic Republic of)',\n",
    "u'Kyrgyz Republic':u'Kyrgyzstan',\n",
    "u'Korea, Rep.':u'Republic of Korea',\n",
    "u'Latin America & Caribbean (all income levels)':'Latin America and the Caribbean',\n",
    "u'Macedonia, FYR':u'The former Yugoslav Republic of Macedonia',\n",
    "u'Korea, Dem. Rep.':u\"Democratic People's Republic of Korea\",\n",
    "u'South Asia':u'Southern Asia',\n",
    "u'Sub-Saharan Africa (all income levels)':u'Sub-Saharan Africa',\n",
    "u'Slovak Republic':u'Slovakia',\n",
    "u'Venezuela, RB':u'Venezuela (Bolivarian Republic of)',\n",
    "u'Yemen, Rep.':u'Yemen ',\n",
    "u'Congo, Dem. Rep.':u'Democratic Republic of the Congo'}\n",
    "\n",
    "#COMTRADE->pop\n",
    "clist4={u\"Bosnia Herzegovina\":\"Bosnia and Herzegovina\",\n",
    "u'Central African Rep.':u'Central African Republic',\n",
    "u'China, Hong Kong SAR':u'China, Hong Kong Special Administrative Region',\n",
    "u'China, Macao SAR':u'China, Macao Special Administrative Region',\n",
    "u'Czech Rep.':u'Czech Republic',\n",
    "u\"Dem. People's Rep. of Korea\":\"Democratic People's Republic of Korea\",\n",
    "u'Dem. Rep. of the Congo':\"Democratic Republic of the Congo\",\n",
    "u'Dominican Rep.':u'Dominican Republic',\n",
    "u'Fmr Arab Rep. of Yemen':u'Yemen ',\n",
    "u'Fmr Ethiopia':u'Ethiopia',\n",
    "u'Fmr Fed. Rep. of Germany':u'Germany',\n",
    "u'Fmr Panama, excl.Canal Zone':u'Panama',\n",
    "u'Fmr Rep. of Vietnam':u'Viet Nam',\n",
    "u\"Lao People's Dem. Rep.\":u\"Lao People's Democratic Republic\",\n",
    "u'Occ. Palestinian Terr.':u'State of Palestine',\n",
    "u'Rep. of Korea':u'Republic of Korea',\n",
    "u'Rep. of Moldova':u'Republic of Moldova',\n",
    "u'Serbia and Montenegro':u'Serbia',\n",
    "u'US Virgin Isds':u'United States Virgin Islands',\n",
    "u'Solomon Isds':u'Solomon Islands',\n",
    "u'United Rep. of Tanzania':u'United Republic of Tanzania',\n",
    "u'TFYR of Macedonia':u'The former Yugoslav Republic of Macedonia',\n",
    "u'USA':u'United States of America',\n",
    "u'USA (before 1981)':u'United States of America',\n",
    "}\n",
    "\n",
    "#Jacobson->pop\n",
    "clist5={u\"Korea, Democratic People's Republic of\":\"Democratic People's Republic of Korea\",\n",
    "u'All countries':u'World',\n",
    "u\"Cote d'Ivoire\":\"C\\xc3\\xb4te d'Ivoire\",\n",
    "u'Iran, Islamic Republic of':u'Iran (Islamic Republic of)',\n",
    "u'Macedonia, Former Yugoslav Republic of':u'The former Yugoslav Republic of Macedonia',\n",
    "u'Congo, Democratic Republic of':u\"Democratic Republic of the Congo\",\n",
    "u'Korea, Republic of':u'Republic of Korea',\n",
    "u'Tanzania, United Republic of':u'United Republic of Tanzania',\n",
    "u'Moldova, Republic of':u'Republic of Moldova',\n",
    "u'Hong Kong, China':u'China, Hong Kong Special Administrative Region',\n",
    "u'All countries.1':\"World\"\n",
    "}\n",
    "\n",
    "#NREL solar->pop\n",
    "clist6={u\"Antigua & Barbuda\":u'Antigua and Barbuda',\n",
    "u\"Bosnia & Herzegovina\":u\"Bosnia and Herzegovina\",\n",
    "u\"Brunei\":u'Brunei Darussalam',\n",
    "u\"Cote d'Ivoire\":\"C\\xc3\\xb4te d'Ivoire\",\n",
    "u\"Iran\":u'Iran (Islamic Republic of)',\n",
    "u\"Laos\":u\"Lao People's Democratic Republic\",\n",
    "u\"Libya\":'Libyan Arab Jamahiriya',\n",
    "u\"Moldova\":u'Republic of Moldova',\n",
    "u\"North Korea\":\"Democratic People's Republic of Korea\",\n",
    "u\"Reunion\":'R\\xc3\\xa9union',\n",
    "u'Sao Tome & Principe':u'Sao Tome and Principe',\n",
    "u'Solomon Is.':u'Solomon Islands',\n",
    "u'St. Lucia':u'Saint Lucia',\n",
    "u'St. Vincent & the Grenadines':u'Saint Vincent and the Grenadines',\n",
    "u'The Bahamas':u'Bahamas',\n",
    "u'The Gambia':u'Gambia',\n",
    "u'Virgin Is.':u'United States Virgin Islands',\n",
    "u'West Bank':u'State of Palestine'\n",
    "}\n",
    "\n",
    "#NREL wind->pop\n",
    "clist7={u\"Antigua & Barbuda\":u'Antigua and Barbuda',\n",
    "u\"Bosnia & Herzegovina\":u\"Bosnia and Herzegovina\",\n",
    "u'Occupied Palestinian Territory':u'State of Palestine',\n",
    "u'China Macao SAR':u'China, Macao Special Administrative Region',\n",
    "u'East Timor':u'Timor-Leste',\n",
    "u'TFYR Macedonia':u'The former Yugoslav Republic of Macedonia',\n",
    "u'IAM-country Total':u'World'\n",
    "}\n",
    "\n",
    "#country entroids->pop\n",
    "clist8={u'Burma':'Myanmar',\n",
    "u\"Cote d'Ivoire\":\"C\\xc3\\xb4te d'Ivoire\",\n",
    "u'Republic of the Congo':u'Congo (Brazzaville)',\n",
    "u'Reunion':'R\\xc3\\xa9union'\n",
    "}\n",
    "\n",
    "def cnc(country): #country name converter\n",
    "    if country in clist1: return clist1[country]\n",
    "    elif country in clist2: return clist2[country]\n",
    "    elif country in clist3: return clist3[country]\n",
    "    elif country in clist4: return clist4[country]\n",
    "    elif country in clist5: return clist5[country]\n",
    "    elif country in clist6: return clist6[country]\n",
    "    elif country in clist7: return clist7[country]\n",
    "    elif country in clist8: return clist8[country]\n",
    "    else: return country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to data repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#path='https://dl.dropboxusercontent.com/u/531697/datarepo/Set/db/\n",
    "path='E:/Dropbox/Public/datarepo/netset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consult the notebook entitled *pop.ipynb* for the details of mining the data from the UN statistics division online database.\n",
    "\n",
    "Due to being the reference database for country names, the cell below needs to be run first, before any other databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#population data\n",
    "pop=pd.read_csv(path+'db/pop.csv').set_index(['Country','Year']).unstack(level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize data and constants\n",
    "data={}\n",
    "countries={i for i in pop.index}\n",
    "years={int(i[1]) for i in pop.columns}\n",
    "dbs={'bp','eia'}\n",
    "datatypes={'prod','cons','emi','res'}\n",
    "allfuels=['oil','coal','gas','nuclear','biofuels','hydro','geo_other','solar','wind']\n",
    "fossils=['oil','coal','gas']+['nrg','nrg_sum']\n",
    "transp=1 #transparency\n",
    "#colorlist=np.array([[166,86,40,transp*255],[153,153,153,transp*255],[152,78,163,transp*255],\n",
    "#                    [228,26,28,transp*255],[247,129,191,transp*255],[55,126,184,transp*255],\n",
    "#                    [82,56,65,transp*255],[255,255,51,transp*255],[77,175,74,transp*255]])/255.0\n",
    "colorlist=np.array([[131,13,9,transp*255],[85,20,52,transp*255],[217,20,14,transp*255],\n",
    "                    [213,9,98,transp*255],[64,185,85,transp*255],[202,200,46,transp*255],\n",
    "                    [106,23,9,transp*255],[251,212,31,transp*255],[112,133,16,transp*255]])/255.0\n",
    "gcolors={allfuels[i]:colorlist[i] for i in range(len(allfuels))}\n",
    "\n",
    "def reset(what='all',datatype='all'):\n",
    "    global data\n",
    "    if what=='all':\n",
    "        #reset all values of database\n",
    "        fuels=allfuels+['nrg','nrg_sum']\n",
    "        data={i:{int(k[1]):{'energy':{j:{k:{l:np.NaN for l in dbs} for k in datatypes}\\\n",
    "                              for j in fuels},'population':long(pop.loc[i][k])*1000,\\\n",
    "                                              'consumer_efficiency':0.5,\\\n",
    "                                              'cumulative_emissions':0}\\\n",
    "                              for k in pop.columns}\\\n",
    "                              #we use population as the default database for country names\n",
    "                              for i in pop.index} \n",
    "    else:\n",
    "        countries=data.keys()\n",
    "        for i in countries:\n",
    "            for j in years:\n",
    "                if datatype=='all':\n",
    "                    data[i][j]['energy'][what]={k:{l:np.NaN for l in dbs} for k in datatypes}\n",
    "                else:\n",
    "                    data[i][j]['energy'][what][datatype]={l:np.NaN for l in dbs}\n",
    "\n",
    "reset()\n",
    "\n",
    "kbpd_to_TWh=365.25*0.001628200 #unit conversion from thousand barrels of oil per day to TWh per year\n",
    "Gboe_to_TWh=1628.2 #unit conversion from thousand million barrels of oil to TWh\n",
    "EJ_to_TWh=277.77 #unit conversion from exa Joule to TWh\n",
    "bcf_to_TWh=0.2931 #unit conversion from billion cubic feet of natural gas to TWh\n",
    "tcf_to_TWh=bcf_to_TWh*1000.0 #unit conversion from trillion cubic feet of natural gas to TWh\n",
    "qbtu_to_TWh=293.297222 #unit conversion from quadrillion British thermal units to TWh\n",
    "mtoe_to_TWh=11.63 #unit conversion million metric tons of oil equivalent to TWh\n",
    "Mtoe_to_TWh=11.63 #unit conversion million metric tons of oil equivalent to TWh\n",
    "Gtoe_to_TWh=11.63*1000 #unit conversion million metric tons of oil equivalent to TWh\n",
    "kgge_to_gm3=1.49 #unit conversion from kilogram of natural gas to cubic meter, based on CH4\n",
    "mtlnge_to_TWh=14.45 #unit conversion million metric tons of gas (LNG) equivalent to TWh\n",
    "cm_to_cf=35.3 #unit conversion from million cubic meters to million cubic feet\n",
    "tcm_to_TWh=tcf_to_TWh*cm_to_cf #unit conversion from trillion cubic meters of natural gas to TWh\n",
    "kgge_to_TWh=kgge_to_gm3*tcf_to_TWh*cm_to_cf*1e-18 #unit conversion from kilogram of natural gas to TWh\n",
    "#mtge_to_TWh=kgge_to_gm3*tcf_to_TWh*cm_to_cf*1e-9 #unit conversion from kilogram of natural gas to TWh\n",
    "mtge_to_GJ=53.6\n",
    "mtge_to_TWh=mtge_to_GJ*1e-9*EJ_to_TWh\n",
    "t_to_st=1.10231 #unit conversion from metric ton to short ton\n",
    "tcoe_to_toe=0.7 #unit conversion from metric tons of coal equivalent to metric tons of oil equivalent\n",
    "mtcoe_to_TWh=tcoe_to_toe*mtoe_to_TWh #unit conversion million metric tons of coal equivalent to TWh\n",
    "#mtcoe_to_TWh=8.141\n",
    "mstcoe_to_TWh=mtcoe_to_TWh*t_to_st #unit conversion million metric short tons of coal equivalent to TWh\n",
    "c_to_co2=44.0/12 #unit conversion from C to CO2 mass\n",
    "\n",
    "carbon_budget=840*c_to_co2 #840 GtC as per http://www.ipcc.ch/report/ar5/wg1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "def stackplotter(country,db='navg',datatype='all',fuels='all',limits=[1965,2015]):\n",
    "    x=np.sort(list(years))\n",
    "    if datatype!='all':\n",
    "        fig, ax = plt.subplots(1,1,subplot_kw=dict(axisbg='#EEEEEE'),figsize=(10,6))\n",
    "        ax.grid(color='white', linestyle='solid')\n",
    "\n",
    "        if type(fuels)==str: \n",
    "            if fuels=='all':fuels=allfuels\n",
    "            else: fuels=[fuels]\n",
    "        ind=np.argsort([np.isnan(np.array([data[country][year]['energy'][fuel][datatype][db] for year in x]).T).sum() for fuel in fuels])\n",
    "        fuels=np.array(fuels)[ind]\n",
    "        colors=[gcolors[fuel] for fuel in fuels]\n",
    "        y=np.array([[data[country][year]['energy'][i][datatype][db] for i in fuels] for year in x]).T\n",
    "\n",
    "        stack_coll=ax.stackplot(x,y,colors=colors)\n",
    "        proxy_rects = [Rectangle((0, 0), 1, 1, fc=pc.get_facecolor()[0]) for pc in stack_coll][::-1]\n",
    "\n",
    "        ax.legend(proxy_rects, fuels[::-1],loc=2,framealpha=0)\n",
    "        if datatype=='emi': ax.set_ylabel('MtCO2',labelpad=10)\n",
    "        else: ax.set_ylabel('TWh',labelpad=10)\n",
    "        ax.set_title(db+' '+datatype)\n",
    "        ax.set_xlim(limits)\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1,2,subplot_kw=dict(axisbg='#EEEEEE'),figsize=(17,5))\n",
    "        datatype=['prod','cons']\n",
    "        ymax=0\n",
    "        for k in range(2): \n",
    "            ax[k].grid(color='white', linestyle='solid')\n",
    "        \n",
    "            if type(fuels)==str: \n",
    "                if fuels=='all':fuels=allfuels\n",
    "                else: fuels=[fuels]\n",
    "            ind=np.argsort([np.isnan(np.array([data[country][year]['energy'][fuel][datatype[k]][db] for year in x]).T).sum() for fuel in fuels])\n",
    "            fuels=np.array(fuels)[ind]\n",
    "            colors=[gcolors[fuel] for fuel in fuels]\n",
    "            y=np.array([[data[country][year]['energy'][i][datatype[k]][db] for i in fuels] for year in x]).T\n",
    "            \n",
    "            stack_coll=ax[k].stackplot(x,y,colors=colors)\n",
    "            proxy_rects = np.array([Rectangle((0, 0), 1, 1, fc=pc.get_facecolor()[0]) for pc in stack_coll][::-1])\n",
    "\n",
    "            ax[k].legend(proxy_rects, fuels[::-1],loc=2,framealpha=0.7)\n",
    "            ax[k].set_ylabel('TWh',labelpad=10)\n",
    "            ax[k].set_title(db+' '+datatype[k])\n",
    "            ax[k].set_xlim(limits)\n",
    "            ymax=max(ymax,ax[k].get_ylim()[1])\n",
    "        for k in range(2): \n",
    "            ax[k].set_ylim([0,ymax])\n",
    "    plt.suptitle(country,fontsize=14,color='green')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keyplotter(d,c=\"royalBlue\",o=1,lw=1):\n",
    "    \n",
    "    x=[]\n",
    "    y=[]\n",
    "    for key in sorted(d.keys()):\n",
    "        x.append(key)\n",
    "        y.append(d[key])\n",
    "    plt.plot(x,y,color=c,alpha=o,lw=lw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subplotter(country,fuel,db,datatype,ax):\n",
    "    try:\n",
    "        ax.plot(subgetter(country,fuel,db,datatype)['x'],subgetter(country,fuel,db,datatype)['y'],label=db+' '+datatype,linewidth=2)\n",
    "    except: print 'ERROR plotting', country, fuel, db, datatype\n",
    "\n",
    "def fracplotter(country,fuel,db,top,down,ax):\n",
    "    try:\n",
    "        ax.plot(fracgetter(country,fuel,db,top,down)['x'],\\\n",
    "            fracgetter(country,fuel,db,top,down)['y'],label=db+' '+top+'/'+down,linewidth=2,linestyle='--')\n",
    "    except: print 'ERROR plotting', country, fuel, db, top+'/'+down\n",
    "        \n",
    "def plotter(country,fuel,db='avg',limits=[1965,2015]):\n",
    "    fig, ax = plt.subplots(1,3,subplot_kw=dict(axisbg='#EEEEEE'),figsize=(17,4))\n",
    "    for i in range(3): ax[i].grid(color='white', linestyle='solid')\n",
    "    \n",
    "    if fuel=='population': \n",
    "        subplotter(country,fuel,'un','population',ax[0])\n",
    "        ax[0].set_ylabel('million',labelpad=14)\n",
    "        ax[0].set_xlim(limits)\n",
    "    elif fuel=='cumulative_emissions': \n",
    "        subplotter(country,fuel,'cumulative','emissions',ax[0])\n",
    "        ax[0].plot(limits,np.ones(len(limits))*carbon_budget,'r--',label='carbon budget')\n",
    "        ax[0].set_ylabel('GtCO2',labelpad=14)\n",
    "        ax[0].set_xlim(limits)\n",
    "    else: \n",
    "        ax[0].set_ylabel('TWh',labelpad=-60)\n",
    "        if fuel in fossils:\n",
    "            ax[1].set_ylabel('TWh',labelpad=-70)\n",
    "            ax[2].set_ylabel('MtCO2',labelpad=-60)\n",
    "            ax1=ax[1].twinx()\n",
    "            ax2=ax[2].twinx()\n",
    "        for i in range(3): ax[i].set_xlim(limits)\n",
    "        if db=='all': db=dbs | {'avg'}\n",
    "        if type(db)==str: db={db}\n",
    "        for i in db:\n",
    "            subplotter(country,fuel,i,'cons',ax[0])\n",
    "            subplotter(country,fuel,i,'prod',ax[0])\n",
    "            if fuel in fossils:\n",
    "                subplotter(country,fuel,i,'res',ax[1])\n",
    "                subplotter(country,fuel,i,'emi',ax[2])\n",
    "                #plot extraction ratio\n",
    "                fracplotter(country,fuel,i,'prod','res',ax1)\n",
    "                #plot carbon intensity\n",
    "                fracplotter(country,fuel,i,'emi','cons',ax2)\n",
    "                \n",
    "    for i in range(3): ax[i].legend(loc=2,framealpha=0.8)\n",
    "    ax[0].set_title(fuel)\n",
    "    if fuel in fossils:\n",
    "        ax1.legend(loc=4,framealpha=0.8)\n",
    "        ax2.legend(loc=4,framealpha=0.8)\n",
    "        ax1.set_ylabel('fraction',labelpad=-50)\n",
    "        ax2.set_ylabel('kgCO2/kWh primary',labelpad=-45)\n",
    "    plt.suptitle(country,fontsize=14,color='green')\n",
    "    plt.show()\n",
    "    \n",
    "def subgetter(country,fuel,db,datatype):\n",
    "    try:\n",
    "        if fuel=='population':\n",
    "            x=np.sort(list(years))\n",
    "            y=[data[country][i]['population']/1000000.0 for i in x]\n",
    "        elif fuel=='cumulative_emissions':\n",
    "            x=np.sort(list(years))\n",
    "            y=[data[country][i]['cumulative_emissions']/1000.0 for i in x]\n",
    "        else:\n",
    "            x=[i for i in np.sort(list(years)) if not np.isnan(data[country][i]['energy'][fuel][datatype][db])]\n",
    "            y=[data[country][i]['energy'][fuel][datatype][db] for i in x]\n",
    "        return {'x':x,'y':y}\n",
    "    except: print 'ERROR getting', country, fuel, db, datatype\n",
    "\n",
    "def fracgetter(country,fuel,db,top,down):\n",
    "    try:\n",
    "        a=subgetter(country,fuel,db,top)['x']\n",
    "        b=subgetter(country,fuel,db,down)['x']\n",
    "        c=np.intersect1d(a,b)\n",
    "        d=np.searchsorted(a,c)\n",
    "        e=np.searchsorted(b,c)\n",
    "        x=a[d[0]:d[::-1][0]+1]\n",
    "        y=np.array(subgetter(country,fuel,db,top)['y'][d[0]:d[::-1][0]+1])/\\\n",
    "          np.array(subgetter(country,fuel,db,down)['y'][e[0]:e[::-1][0]+1])\n",
    "        return {'x':x,'y':y}\n",
    "    except: print 'ERROR getting', country, fuel, db, top+'/'+down\n",
    "        \n",
    "def getter(country,fuel,db='avg'):\n",
    "    if fuel=='population': \n",
    "        return subgetter(country,fuel,'un','population')\n",
    "    elif fuel=='cumulative_emissions': \n",
    "        return subgetter(country,fuel,'cumulative','emissions')\n",
    "    else: \n",
    "        if db=='all': db=dbs | {'avg'}\n",
    "        if type(db)==str: db={db}\n",
    "        aux={}\n",
    "        for i in db:\n",
    "            aux[i]={}\n",
    "            for datatype in {'cons','prod','emi','res'}:\n",
    "                aux[i][datatype]=subgetter(country,fuel,i,datatype)\n",
    "        return aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def interpolate(d,years,gfit=2,depth=1,polyorder=1,override=False,ends=False):\n",
    "#d=helper\n",
    "#years=[2015]\n",
    "#gfit=1\n",
    "#depth=extrapolatedict[fuel]\n",
    "#polyorder=1\n",
    "#override=True\n",
    "#ends=True\n",
    "#if True:\n",
    "    #depth * length of interpolation substrings will be taken to the left and right\n",
    "    #for example for {1971:5,1972:6,1973:7,1974:5} interpolating it over 1969-1990\n",
    "    #for the section 1960-1970 (2 elements) the values from 1972,1973,1974 (3 elements) will be taken with depth 1.5\n",
    "    #for the section 1974-1990 (15 elements) all values  (4 elements) will be taken to extrapolate\n",
    "    #override to extend interpolation to edges, i.e. extrapolate\n",
    "    if (gfit>2): \n",
    "        print 'interpolate takes only 1 (polynomial) or 2 (exponential) as 3rd argument [default=2]'\n",
    "        return\n",
    "    mydict={}\n",
    "    if d!={}:\n",
    "        missing_points=[[]]\n",
    "        onbeginning=False\n",
    "        onend=False\n",
    "        for year in years:\n",
    "            if year not in d.keys():\n",
    "                missing_points[-1].append(year)\n",
    "            else:\n",
    "                missing_points.append([])\n",
    "        for m in missing_points:\n",
    "            if m:\n",
    "                fit=gfit\n",
    "\n",
    "                #if only one point, set min extrapolation depth to 2\n",
    "                if (len(m)==1): depth=max(depth,2)\n",
    "                \n",
    "                #check if it is ends of the interval, \n",
    "                if ((m[-1]<np.sort(d.keys())[0])|(m[0]>np.sort(d.keys())[-1])): \n",
    "                    #if not set to override then extrapolate mean only\n",
    "                    if not override: \n",
    "                        fit=0                    \n",
    "\n",
    "                if fit==0: #take average\n",
    "                    y = {k: d[k] for k in set(d.keys()).intersection(range(int(max(min(years),min(m)-int(3))),\\\n",
    "                                                                           int(min(max(years),max(m)+int(3))+1)))}\n",
    "                    #returned empty, on beginning\n",
    "                    if y=={}:\n",
    "                        if m[-1]<np.sort(d.keys())[0]:y={np.sort(d.keys())[0]:d[np.sort(d.keys())[0]]}\n",
    "                        elif m[0]>np.sort(d.keys())[-1]:y={np.sort(d.keys())[-1]:d[np.sort(d.keys())[-1]]}\n",
    "                    for i in range(len(m)):\n",
    "                        mydict[m[i]]=np.mean(y.values())\n",
    "                elif fit==1:\n",
    "                    #intersector\n",
    "                    y = {k: d[k] for k in set(d.keys()).intersection(range(int(max(min(years),\\\n",
    "                                min(m)-int(depth*len(m)))),int(min(max(years),max(m)+int(depth*len(m)))+1)))}\n",
    "                    #returned empty\n",
    "                    if y=={}:\n",
    "                        if m[-1]<np.sort(d.keys())[0]:y={np.sort(d.keys())[0]:d[np.sort(d.keys())[0]]}\n",
    "                        elif m[0]>np.sort(d.keys())[-1]:y={np.sort(d.keys())[-1]:d[np.sort(d.keys())[-1]]}\n",
    "                            \n",
    "                    w = np.polyfit(y.keys(),y.values(),polyorder) # obtaining regression parameters\n",
    "                    if (polyorder==1):\n",
    "                        intersector=w[0]*np.array(m)+w[1]\n",
    "                    else:\n",
    "                        intersector=w[0]*np.array(m)*np.array(m)+w[1]*np.array(m)+w[2]\n",
    "                    for i in range(len(m)):\n",
    "                        mydict[m[i]]=max(0,intersector[i])\n",
    "                else:\n",
    "                    #exponential intersector\n",
    "                    y = {k: d[k] for k in set(d.keys()).intersection(range(int(max(min(years),\\\n",
    "                                min(m)-int(depth*len(m)))),int(min(max(years),max(m)+int(depth*len(m)))+1)))}\n",
    "                    #returned empty\n",
    "                    if y=={}:\n",
    "                        if m[-1]<np.sort(d.keys())[0]:y={np.sort(d.keys())[0]:d[np.sort(d.keys())[0]]}\n",
    "                        elif m[0]>np.sort(d.keys())[-1]:y={np.sort(d.keys())[-1]:d[np.sort(d.keys())[-1]]}\n",
    "                    \n",
    "                    w = np.polyfit(y.keys(),np.log(y.values()),1) # obtaining log regression parameters (exp fitting)\n",
    "                    intersector=np.exp(w[1])*np.exp(w[0]*np.array(m))\n",
    "                    for i in range(len(m)):\n",
    "                        mydict[m[i]]=max(0,intersector[i])\n",
    "                    \n",
    "                #record ends adjustment beginning and end\n",
    "                if ends:\n",
    "                    if (m[-1]<np.sort(d.keys())[0]):\n",
    "                        onbeginning=True\n",
    "                        beginning=m[-1]\n",
    "                    if (m[0]>np.sort(d.keys())[-1]): \n",
    "                        onend=True\n",
    "                        end=m[0]\n",
    "        #finish ends adjustment\n",
    "        if ends:\n",
    "            if onbeginning:\n",
    "                #calculate adjustment scaler\n",
    "                if (mydict[beginning]==0): scaler=0\n",
    "                elif (beginning+1 in d): scaler=d[beginning+1]*1.0/mydict[beginning]\n",
    "                else: scaler=d[np.sort(d.keys())[0]]*1.0/mydict[beginning]\n",
    "                #readjust data\n",
    "                for year in mydict:\n",
    "                    if (year<=beginning):\n",
    "                        mydict[year]*=scaler\n",
    "            if onend:\n",
    "                #calculate adjustment scaler\n",
    "                if (mydict[end]==0): scaler=0\n",
    "                elif (end-1 in d): scaler=d[end-1]*1.0/mydict[end]\n",
    "                else: scaler=d[np.sort(d.keys())[-1]]*1.0/mydict[end]\n",
    "                #readjust data\n",
    "                for year in mydict:\n",
    "                    if (year>=end):\n",
    "                        mydict[year]*=scaler\n",
    "\n",
    "    #return interpolated points\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scurve(x):\n",
    "    lamda=8 #curve steepness control\n",
    "    mu=0.5\n",
    "    return 1/(1+np.exp(-lamda*(x-mu)))\n",
    "x=np.arange(100)/100.0\n",
    "#plt.plot(x,[scurve(i) for i in x],c='#dd1c77',lw=2)\n",
    "#plt.xlabel('input (normalized time)')\n",
    "#plt.ylabel('output (effect strength)')\n",
    "#plt.text(0.04, 0.95, u'$f(t)=1/[1+e^{-λ(t-μ)}]$\\n$λ=12$\\n$μ=0.5$',\n",
    "#    horizontalalignment='left',\n",
    "#    verticalalignment='top',size=14,alpha=0.6)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Country ISO codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cc=pd.read_excel(path+'db/Country Code and Name ISO2 ISO3.xls')\n",
    "#http://unstats.un.org/unsd/tradekb/Attachment321.aspx?AttachmentType=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ccs=cc['Country Code'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Country neighbor list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighbors=pd.read_csv(path+'db/contry-geotime.csv')\n",
    "#https://raw.githubusercontent.com/ppKrauss/country-geotime/master/data/contry-geotime.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#country name converter from iso to comtrade and back\n",
    "iso2c={}\n",
    "isoc2={}\n",
    "for i in cc.T.iteritems():\n",
    "    iso2c[i[1][0]]=i[1][1]\n",
    "    isoc2[i[1][1]]=i[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#country name converter from pop to iso\n",
    "pop2iso={}\n",
    "for i in cc.T.iteritems():\n",
    "    pop2iso[cnc(i[1][1])]=int(i[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#country name converter from alpha 2 to iso\n",
    "c2iso={}\n",
    "for i in neighbors.T.iteritems():\n",
    "    c2iso[str(i[1][0])]=i[1][1]\n",
    "c2iso['NA']=c2iso['nan'] #adjust for namibia\n",
    "c2iso.pop('nan');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create country neighbor adjacency list based on iso country number codes\n",
    "c2neighbors={}\n",
    "for i in neighbors.T.iteritems():\n",
    "    z=str(i[1][4]).split(' ')\n",
    "    if (str(i[1][1])!='nan'): c2neighbors[int(i[1][1])]=[c2iso[k] for k in z if k!='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extend iso codes not yet encountered\n",
    "iso2c[729]=\"Sudan\"\n",
    "iso2c[531]=\"Curacao\"\n",
    "iso2c[535]=\"Bonaire, Sint Eustatius and Saba\"\n",
    "iso2c[728]=\"South Sudan\"\n",
    "iso2c[534]=\"Sint Maarten (Dutch part)\"\n",
    "iso2c[652]=\"Saint Barthélemy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdp=pd.read_excel(path+'db/GDP.xls',skiprows=2)\n",
    "#http://unstats.un.org/unsd/snaama/downloads/Download-GDPcurrent-USD-countries.xls\n",
    "#imports are in current terms, so we need also current terms here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdpc={}\n",
    "for i in gdp.T.iteritems():\n",
    "    if (i[1][1]=='Total Value Added'):\n",
    "        country=cnc(i[1][0])\n",
    "        if country not in gdpc:gdpc[country]={}\n",
    "        for j in range(1970,2015):\n",
    "            gdpc[country][j]=i[1][j+2-1970]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests, StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#r = requests.get('http://gothos.info/resource_files/country_centroids.zip')\n",
    "# use StringIO.StringIO(r.content) below if requests is used\n",
    "\n",
    "z = zipfile.ZipFile(path+'../universal/country_centroids.zip')\n",
    "coord=pd.read_csv(z.open('country_centroids_all.csv'),sep='\\t')\\\n",
    "    .drop(['DMS_LAT','DMS_LONG','MGRS','JOG','DSG','FULL_NAME',\\\n",
    "       'ISO3136','AFFIL','FIPS10','MOD_DATE'],axis=1)\n",
    "coord.columns=['LAT','LONG','Country']\n",
    "coord=coord.set_index('Country',drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create normalized distance matrix of countries\n",
    "names=[]\n",
    "for i in coord.index:\n",
    "    names.append(cnc(i))\n",
    "coord['NAME']=names\n",
    "coord=coord.set_index('NAME',drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "def distance(i,j):\n",
    "    if i in coord.index and j in coord.index:\n",
    "        return haversine(coord.loc[i]['LONG'],coord.loc[i]['LAT'],\n",
    "                    coord.loc[j]['LONG'],coord.loc[j]['LAT'])\n",
    "    else: return 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formats `data` dictionary into `json` format for epxloration in visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tradealpha={}\n",
    "goodcountries=sorted(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save with zeros\n",
    "def save0(sd,countrylist=[],db='navg3'):\n",
    "    try:\n",
    "        import zlib\n",
    "        compression = zipfile.ZIP_DEFLATED\n",
    "    except:\n",
    "        compression = zipfile.ZIP_STORED\n",
    "    print 'saving... ',sd,\n",
    "    popsave={}\n",
    "    countries=[]\n",
    "    if countrylist==[]:\n",
    "        c=sorted(goodcountries)\n",
    "    \n",
    "    else: c=countrylist\n",
    "    for country in c:\n",
    "        popdummy={}\n",
    "        tosave=[]\n",
    "        for year in data[country]:\n",
    "            popdummy[year]=data[country][year]['population']\n",
    "            for fuel in data[country][year]['energy']:\n",
    "            #for fuel in allfuels:\n",
    "                if fuel not in {'nrg','nrg_sum'}:\n",
    "                    tosave.append({\"t\":year,\"u\":fuel,\"g\":\"f\",\"q1\":\"pp\",\"q2\":999,\n",
    "                               \"s\":round(0 if ((db in data[country][year]['energy'][fuel]['prod']) \\\n",
    "                                          and (np.isnan(data[country][year]['energy'][fuel]['prod'][db]))) else \\\n",
    "                               data[country][year]['energy'][fuel]['prod'][db] if \\\n",
    "                                   db in data[country][year]['energy'][fuel]['prod'] else 0,3)\n",
    "                               })\n",
    "                    tosave.append({\"t\":year,\"u\":fuel,\"g\":\"m\",\"q1\":\"cc\",\"q2\":999,\n",
    "                               \"s\":round(0 if ((db in data[country][year]['energy'][fuel]['cons']) \\\n",
    "                                          and (np.isnan(data[country][year]['energy'][fuel]['cons'][db]))) else \\\n",
    "                               data[country][year]['energy'][fuel]['cons'][db] if \\\n",
    "                                   db in data[country][year]['energy'][fuel]['cons'] else 0,3)\n",
    "                              })\n",
    "                    \n",
    "        #no import export flows on global\n",
    "        if country not in {\"World\"}:\n",
    "            flowg={\"Import\":\"f\",\"Export\":\"m\",\"Re-Export\":\"m\",\"Re-Import\":\"f\"}\n",
    "            if country in tradealpha:\n",
    "                for year in tradealpha[country]:\n",
    "                    for fuel in tradealpha[country][year]:\n",
    "                        for flow in tradealpha[country][year][fuel]:\n",
    "                            for partner in tradealpha[country][year][fuel][flow]:\n",
    "                                tosave.append({\"t\":int(float(year)),\"u\":fuel,\"g\":flowg[flow],\"q1\":flow,\"q2\":partner,\n",
    "                                           \"s\":round(tradealpha[country][year][fuel][flow][partner],3)\n",
    "                                           })\n",
    "        \n",
    "        if tosave!=[]:\n",
    "            countries.append(country)\n",
    "            popsave[country]=popdummy\n",
    "        \n",
    "        file(path+'json/'+str(sd)+'/data.json','w').write(json.dumps(tosave)) \n",
    "        zf = zipfile.ZipFile(path+'json/'+str(sd)+'/'+str(country.encode('utf-8').replace('/','&&'))+'.zip', mode='w')\n",
    "        zf.write(path+'json/'+str(sd)+'/data.json','data.json',compress_type=compression)\n",
    "        zf.close()\n",
    "        \n",
    "    #save all countries list\n",
    "    file(path+'json/'+str(sd)+'/'+'countries.json','w').write(json.dumps(countries)) \n",
    "    \n",
    "    #save countries populations\n",
    "    file(path+'json/'+str(sd)+'/'+'pop.json','w').write(json.dumps(popsave))     \n",
    "    \n",
    "    print ' done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save without zeroes\n",
    "def save(sd,countrylist=[],db='navg3'):\n",
    "    try:\n",
    "        import zlib\n",
    "        compression = zipfile.ZIP_DEFLATED\n",
    "    except:\n",
    "        compression = zipfile.ZIP_STORED\n",
    "    print 'saving... ',sd,\n",
    "    popsave={}\n",
    "    countries=[]\n",
    "    if countrylist==[]:\n",
    "        c=sorted(goodcountries)\n",
    "    \n",
    "    else: c=countrylist\n",
    "    for country in c:\n",
    "        popdummy={}\n",
    "        tosave=[]\n",
    "        for year in data[country]:\n",
    "            popdummy[year]=data[country][year]['population']\n",
    "            for fuel in data[country][year]['energy']:\n",
    "            #for fuel in allfuels:\n",
    "                if fuel not in {'nrg','nrg_sum'}:\n",
    "                    tosave.append({\"t\":year,\"u\":fuel,\"g\":\"f\",\"q1\":\"pp\",\"q2\":999,\n",
    "                               \"s\":round(0 if ((db in data[country][year]['energy'][fuel]['prod']) \\\n",
    "                                          and (np.isnan(data[country][year]['energy'][fuel]['prod'][db]))) else \\\n",
    "                               data[country][year]['energy'][fuel]['prod'][db] if \\\n",
    "                                   db in data[country][year]['energy'][fuel]['prod'] else 0,3)\n",
    "                               })\n",
    "                    tosave.append({\"t\":year,\"u\":fuel,\"g\":\"m\",\"q1\":\"cc\",\"q2\":999,\n",
    "                               \"s\":round(0 if ((db in data[country][year]['energy'][fuel]['cons']) \\\n",
    "                                          and (np.isnan(data[country][year]['energy'][fuel]['cons'][db]))) else \\\n",
    "                               data[country][year]['energy'][fuel]['cons'][db] if \\\n",
    "                                   db in data[country][year]['energy'][fuel]['cons'] else 0,3)\n",
    "                              })\n",
    "                    \n",
    "        #no import export flows on global\n",
    "        if country not in {\"World\"}:\n",
    "            flowg={\"Import\":\"f\",\"Export\":\"m\",\"Re-Export\":\"m\",\"Re-Import\":\"f\"}\n",
    "            if country in tradealpha:\n",
    "                for year in tradealpha[country]:\n",
    "                    for fuel in tradealpha[country][year]:\n",
    "                        for flow in tradealpha[country][year][fuel]:\n",
    "                            for partner in tradealpha[country][year][fuel][flow]:\n",
    "                                tosave.append({\"t\":int(float(year)),\"u\":fuel,\"g\":flowg[flow],\"q1\":flow,\"q2\":partner,\n",
    "                                           \"s\":round(tradealpha[country][year][fuel][flow][partner],3)\n",
    "                                           })\n",
    "        \n",
    "        tosave2=[] #eliminate zeroes\n",
    "        for item in tosave:\n",
    "            if item[\"s\"]!=0: tosave2.append(item)\n",
    "        \n",
    "        if tosave2!=[]:\n",
    "            countries.append(country)\n",
    "            popsave[country]=popdummy\n",
    "        \n",
    "        file(path+'json/'+str(sd)+'/data.json','w').write(json.dumps(tosave2)) \n",
    "        zf = zipfile.ZipFile(path+'json/'+str(sd)+'/'+str(country.encode('utf-8').replace('/','&&'))+'.zip', mode='w')\n",
    "        zf.write(path+'json/'+str(sd)+'/data.json','data.json',compress_type=compression)\n",
    "        zf.close()\n",
    "        \n",
    "    #save all countries list\n",
    "    file(path+'json/'+str(sd)+'/'+'countries.json','w').write(json.dumps(countries)) \n",
    "    \n",
    "    #save countries populations\n",
    "    file(path+'json/'+str(sd)+'/'+'pop.json','w').write(json.dumps(popsave))     \n",
    "    \n",
    "    print ' done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to automatically save this notebook as a Python script to be loaded in other notebooks. In order to prevent an infitine loop, there is a trigger variable `initlive`. PLease go to the cell on the bottom to set it to `True` and then run the cell with the `system` magic in it. On external call, `initilive` will default to `False`, thus preventing the infinite loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initlive=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if initlive:\n",
    "    %system jupyter nbconvert --to script init.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initlive=True"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
